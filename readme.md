# Permutation Feature Importance For Deep Learning Models
Permutation feature importance is a model inspection technique that can be used for any fitted estimator when the data is tabular. This is especially useful for non-linear or opaque estimators. The permutation feature importance is defined to be the decrease in a model score when a single feature value is randomly shuffled. 
<br>
<br>
This repository contains modified code for permutation feature importance which can be used in Deep Learning models specifically dealing with Time-Series Data
